% Experiments on robust learning of the ALARM Bayes net.
% Compare the performance of MLE_noNoise, MLE, RANSAC, and Filtering  (performance = error in total variation distance) for various eps.
% N = number of samples, eps = fraction of corruption, d = number of variables, m = number of conditional probabilities.

% ALARM:
%   I. A. Beinlich, H. J. Suermondt, R. M. Chavez, and G. F. Cooper.
%   The ALARM Monitoring System: A Case Study with Two Probabilistic Inference Techniques for Belief Networks.
%   In Proceedings of the 2nd European Conference on Artificial Intelligence in Medicine, pages 247-256. 1989.

clear
rng(1, 'twister');

% The ALARM network (structure and conditional probabilites).
parent = {[];
	[];
	[1, 2];
	[1, 2, 3];
	[];
	[];
	[];
	[];
	[8];
	[8, 9];
	[];
	[];
	[];
	[];
	[14];
	[];
	[];
	[17];
	[17, 18];
	[17, 18, 19];
	[16, 19, 20];
	[16, 19, 20, 21];
	[14, 15, 11, 21, 22];
	[14, 15, 11, 21, 22, 23];
	[14, 15, 23, 24];
	[14, 15, 23, 24, 25];
	[25, 26];
	[25, 26, 27];
	[2];
	[1, 2];
	[1, 2, 30];
	[27, 28, 23, 24];
	[27, 28, 23, 24, 32];
	[14, 15, 23, 24];
	[14, 15, 23, 24, 34];
	[12, 25, 26];
	[12, 25, 26, 36];
	[13];
	[13, 38];
	[14, 15, 13];
	[14, 15, 11, 21, 22];
	[14, 15, 11, 21, 22, 41];
	[30, 31];
	[30, 31, 43];
	[30, 31];
	[30, 31, 45];
	[36, 37, 40];
	[36, 37, 40, 47];
	[27, 28, 7, 47, 48, 9, 10];
	[49];
	[49, 50];
	[50, 51, 3, 4];
	[50, 51, 3, 4, 52];
	[52, 53, 9, 10];
	[52, 53, 9, 10, 54];
	[5, 50, 51];
	[5, 50, 51, 56];
	[6, 50, 51];
	[6, 50, 51, 58];
	[6, 50, 51];
	[6, 50, 51, 60]};

p = [0.800000...
	0.950000...
	0.010000 0.010000 0.010000 0.050000...
	0.010101 0.500000 0.494949 0.500000 0.040404 0.500000 0.947368 0.500000...
	0.950000...
	0.900000...
	0.900000...
	0.990000...
	0.010000 0.300000...
	0.010101 0.500000 0.571429 0.500000...
	0.960000...
	0.950000...
	0.990000...
	0.050000...
	0.031579 0.500000...
	0.900000...
	0.050000...
	0.947368 0.500000...
	0.020000 0.940000 0.940000 0.940000...
	0.948980 0.500000 0.166667 0.010638 0.166667 0.989362 0.166667 0.989362...
	0.020000 0.020000 0.020000 0.980000 0.020000 0.020000 0.020000 0.980000...
	0.010204 0.500000 0.010204 0.500000 0.010204 0.500000 0.500000 0.010204 0.010204 0.500000 0.010204 0.500000 0.989796 0.500000 0.500000 0.989796...
	0.020000 0.020000 0.020000 0.020000 0.020000 0.020000 0.980000 0.020000 0.020000 0.020000 0.020000 0.020000 0.020000 0.020000 0.020000 0.980000 0.020000 0.020000 0.980000 0.020000 0.020000 0.020000 0.020000 0.980000 0.020000 0.020000 0.980000 0.020000 0.020000 0.020000 0.020000 0.980000...
	0.010204 0.500000 0.010204 0.500000 0.010204 0.500000 0.010204 0.500000 0.693878 0.500000 0.030612 0.500000 0.500000 0.989796 0.989796 0.500000 0.030612 0.500000 0.010204 0.500000 0.989796 0.500000 0.010204 0.500000 0.010204 0.500000 0.489796 0.500000 0.010204 0.500000 0.500000 0.010204 0.591837 0.500000 0.010204 0.500000 0.500000 0.010204 0.010204 0.500000 0.010204 0.500000 0.693878 0.500000 0.010204 0.500000 0.500000 0.989796 0.591837 0.500000 0.010204 0.500000 0.500000 0.010204 0.010204 0.500000 0.010204 0.500000 0.693878 0.500000 0.010204 0.500000 0.500000 0.989796...
	0.020000 0.980000 0.980000 0.020000 0.020000 0.020000 0.980000 0.050000 0.980000 0.020000 0.020000 0.110000 0.980000 0.020000 0.020000 0.110000...
	0.010204 0.500000 0.500000 0.989796 0.500000 0.010204 0.969388 0.500000 0.989796 0.500000 0.010204 0.500000 0.500000 0.989796 0.989474 0.200000 0.500000 0.010204 0.989796 0.500000 0.010204 0.500000 0.988764 0.090909 0.500000 0.010204 0.989796 0.500000 0.010204 0.500000 0.988764 0.090909...
	0.980000 0.980000 0.040000 0.010000...
	0.500000 0.500000 0.500000 0.500000 0.958333 0.500000 0.090909 0.500000...
	0.100000 0.990000...
	0.010000 0.900000 0.010000 0.050000...
	0.040404 0.500000 0.900000 0.500000 0.010101 0.500000 0.947368 0.500000...
	0.020000 0.020000 0.980000 0.980000 0.020000 0.020000 0.980000 0.980000 0.020000 0.980000 0.020000 0.980000 0.020000 0.980000 0.020000 0.980000...
	0.010204 0.500000 0.989796 0.500000 0.500000 0.010204 0.500000 0.989796 0.989796 0.500000 0.010204 0.500000 0.500000 0.010204 0.500000 0.989796 0.989796 0.500000 0.500000 0.010204 0.010204 0.500000 0.500000 0.989796 0.989796 0.500000 0.500000 0.010204 0.010204 0.500000 0.500000 0.989796...
	0.020000 0.980000 0.020000 0.020000 0.020000 0.020000 0.020000 0.980000 0.980000 0.020000 0.020000 0.980000 0.980000 0.020000 0.020000 0.980000...
	0.010204 0.500000 0.500000 0.989796 0.489796 0.500000 0.989796 0.500000 0.989796 0.500000 0.010204 0.500000 0.489796 0.500000 0.500000 0.010204 0.500000 0.010204 0.387755 0.500000 0.010204 0.500000 0.500000 0.989796 0.500000 0.010204 0.387755 0.500000 0.010204 0.500000 0.500000 0.989796...
	0.000000 0.010000 0.000000 0.040000 0.000000 0.010000 0.010000 0.980000...
	0.000000 0.500000 0.040404 0.500000 0.000000 0.500000 0.989583 0.500000 0.010000 0.500000 0.040404 0.500000 0.040404 0.500000 0.500000 0.500000...
	0.800000 0.050000...
	0.950000 0.500000 0.947368 0.500000...
	0.900000 0.050000 0.900000 0.050000 0.990000 0.950000 0.990000 0.950000...
	0.020000 0.700000 0.020000 0.050000 0.980000 0.700000 0.980000 0.090000 0.690000 0.840000 0.020000 0.100000 0.020000 0.980000 0.020000 0.980000 0.980000 0.020000 0.980000 0.020000 0.060000 0.980000 0.020000 0.980000 0.980000 0.020000 0.980000 0.020000 0.060000 0.980000 0.020000 0.980000...
	0.010204 0.500000 0.833333 0.642857 0.010204 0.500000 0.789474 0.200000 0.500000 0.989796 0.966667 0.571429 0.500000 0.989796 0.989011 0.111111 0.967742 0.289855 0.937500 0.702381 0.989796 0.500000 0.777778 0.100000 0.010204 0.500000 0.500000 0.918367 0.010204 0.500000 0.500000 0.612245 0.500000 0.918367 0.010204 0.500000 0.500000 0.010204 0.010204 0.500000 0.893617 0.166667 0.500000 0.989796 0.591837 0.500000 0.500000 0.989796 0.500000 0.918367 0.010204 0.500000 0.500000 0.010204 0.010204 0.500000 0.893617 0.166667 0.500000 0.989796 0.591837 0.500000 0.500000 0.989796...
	0.010000 0.010000 0.700000 0.700000...
	0.040404 0.500000 0.959596 0.500000 0.966667 0.500000 0.966667 0.500000...
	0.010000 0.010000 0.950000 0.950000...
	0.040404 0.500000 0.959596 0.500000 0.800000 0.500000 0.800000 0.500000...
	0.010000 0.010000 0.010000 0.010000 0.980000 0.010000 0.980000 0.010000...
	0.010101 0.500000 0.010101 0.500000 0.989899 0.500000 0.010101 0.500000 0.500000 0.500000 0.303030 0.500000 0.500000 0.500000 0.303030 0.500000...
	0.990000 0.990000 0.300000 0.300000 0.990000 0.950000 0.300000 0.300000 0.990000 0.950000 0.050000 0.050000 0.990000 0.950000 0.050000 0.050000 0.990000 0.950000 0.300000 0.300000 0.990000 0.950000 0.050000 0.050000 0.950000 0.950000 0.050000 0.050000 0.950000 0.950000 0.050000 0.050000 0.990000 0.990000 0.300000 0.300000 0.990000 0.950000 0.300000 0.300000 0.990000 0.950000 0.010000 0.010000 0.990000 0.950000 0.010000 0.010000 0.990000 0.950000 0.300000 0.300000 0.990000 0.950000 0.010000 0.010000 0.950000 0.950000 0.010000 0.010000 0.950000 0.950000 0.010000 0.010000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.900000 0.900000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000 0.990000 0.990000 0.700000 0.700000...
	0.050000 0.900000...
	0.947368 0.500000 0.900000 0.500000...
	0.010000 0.010000 0.010000 0.010000 0.010000 0.010000 0.690000 0.690000 0.010000 0.950000 0.980000 0.980000 0.010000 0.950000 0.980000 0.980000...
	0.010101 0.500000 0.040404 0.500000 0.696970 0.500000 0.696970 0.500000 0.040404 0.500000 0.959596 0.500000 0.967742 0.500000 0.967742 0.500000 0.191919 0.500000 0.800000 0.500000 0.500000 0.500000 0.500000 0.500000 0.191919 0.500000 0.800000 0.500000 0.500000 0.500000 0.500000 0.500000...
	0.010000 0.010000 0.100000 0.100000 0.010000 0.050000 0.550000 0.550000 0.010000 0.750000 0.900000 0.900000 0.010000 0.750000 0.900000 0.900000...
	0.010101 0.500000 0.010101 0.500000 0.666667 0.500000 0.666667 0.500000 0.010101 0.500000 0.894737 0.500000 0.888889 0.500000 0.888889 0.500000 0.090909 0.500000 0.800000 0.500000 0.900000 0.500000 0.900000 0.500000 0.090909 0.500000 0.800000 0.500000 0.900000 0.500000 0.900000 0.500000...
	0.010000 0.300000 0.010000 0.010000 0.010000 0.010000 0.980000 0.980000...
	0.010101 0.500000 0.571429 0.500000 0.989899 0.500000 0.989899 0.500000 0.595960 0.500000 0.010101 0.500000 0.500000 0.500000 0.500000 0.500000...
	0.333333 0.333333 0.010000 0.010000 0.333333 0.010000 0.980000 0.980000...
	0.500000 0.500000 0.500000 0.500000 0.989899 0.500000 0.989899 0.500000 0.500000 0.500000 0.010101 0.500000 0.500000 0.500000 0.500000 0.500000...
	0.333333 0.333333 0.010000 0.010000 0.333333 0.010000 0.980000 0.980000...
	0.500000 0.500000 0.500000 0.500000 0.989899 0.500000 0.989899 0.500000 0.500000 0.500000 0.010101 0.500000 0.500000 0.500000 0.500000 0.500000];

for eps = 0.05:0.05:0.5
    d = size(parent, 1);
    deg = zeros(d, 1);
    m = 0;
    for i = 1:d
        deg(i) = numel(parent{i});
        m = m + 2^deg(i);
    end
    fprintf('d = %d, m = %d, eps = %f\n', d, m, eps); 
    
    % Take N samples from the ground-truth BN.
    N = 10^6;
    X = zeros(round((1-eps)*N), d);
    k = 0;
    for i = 1:d
        for j = 1:2^deg(i)
            parent_config = dec2bin(j-1, deg(i)) - '0';
            k = k + 1;
            matched_rows = all(bsxfun(@eq, X(:, parent{i}), parent_config), 2);
            X(matched_rows, i) = rand(sum(matched_rows), 1) < p(k);
        end
    end

    % Evaluate MLE without noise (gold standard).
    p_MLE_noNoise = empirical_bn(parent, X);
    fprintf('\td_TV(p, p_MLE_noNoise) = %f\n', dtv_bn(parent, p, p_MLE_noNoise));

    % eps-fraction of the samples are corrupted.
    % Choose a corruption method from below (or create your own).

    % BEGIN: corrupted samples from a product distribution.
    % p_noise = rand(1, n) .* 1/5 + 0.4;
    % Y = rand(eps*N, n);
    % Y = bsxfun(@le, Y, p_noise);
    % END: corrupted samples from a product distribution.
    
    % BEGIN: corrupted samples from another BN that has a random structure (with similar m).
    noise_target_m = m;
    noise_deg = zeros(d, 1);
    noise_m = d;
    while (noise_m < noise_target_m)
        i = randi(d);
        if (noise_deg(i) < i-1)
            noise_m = noise_m - 2^noise_deg(i) + 2^(noise_deg(i)+1);
            noise_deg(i) = noise_deg(i) + 1;
        end
    end
    p_noise = zeros(noise_m, 1);
    % The conditional probabilities are drawn i.i.d from [1/4, 3/4].
    % Draw eps*N corrupted samples.
	Y = zeros(round(eps*N), d);
    k = 0;
    for i = 2:d
        parent_noise_i = randsample(i-1, noise_deg(i))';
        for j = 1:2^noise_deg(i)
            k = k + 1;
            if (rand() > 0.5)
                p_noise_k = rand(1)/4 + 3/4;
            else
                p_noise_k = rand(1)/4;
            end
            % Pi(i, j) == 1 if all parents' values match.
            matched_rows = all(bsxfun(@eq, Y(:, parent_noise_i), j), 2);
            Y(matched_rows, i) = rand(sum(matched_rows), 1) < p_noise_k;
        end
    end
    % END: corrupted samples from another BN.
    
    X = [X; Y];
    N = size(X, 1);

    % Evaluate MLE (i.e., empirical conditional mean) as baseline #1.
    p_MLE = empirical_bn(parent, X);
    fprintf('\td_TV(p, p_MLE) = %f\n', dtv_bn(parent, p, p_MLE));

    % Evaluate RANSAC as baseline #2.
    ransac_N = round(eps*N);
    nItr_ransac = 5;
    min_dtv_ransac = 1;
    for ransac_itr = 1:nItr_ransac
        ransac_X = X(randsample(1:N, ransac_N), :);
        p_ransac = empirical_bn(parent, ransac_X);
        min_dtv_ransac = min(min_dtv_ransac, dtv_bn(parent, p, p_ransac));
    end
    fprintf('\td_TV(p, p_RANSAC) = %f\n', min_dtv_ransac);
    
    % Evaluate Filtering (our method).
    
    % Expand the domain size from d to m.  Fill in the unknown information with emperical mean.
    % Compute and store (F(X,q)-q).
    p_empirical_cond_prob = empirical_bn(parent, X);  % q = p_empirical_cond_prob.
    Fxq_minus_q = zeros(N, m);
    k = 0;
    % Sparse matrix is not required because ALARM is small enough.
    % Do not loop over N -- too slow.
    for i = 1:d
        for j = 1:2^deg(i)
            parent_config = dec2bin(j-1, deg(i)) - '0';
            k = k + 1;  % k = (i, j)
            if deg(i) == 0
                Fxq_minus_q(:, k) = X(:, i) - p_empirical_cond_prob(i);
            else
                matched_config = all(bsxfun(@eq, X(:, parent{i}), parent_config), 2);
                Fxq_minus_q(matched_config, k) = X(matched_config, i) - p_empirical_cond_prob(i);
                Fxq_minus_q(~matched_config, k) = 0;
            end
        end
    end
    
    % The full version of the filtering algorithm should repeat until the top eigenvalue is small enough.
    % In our experiment, we only run one iteration, which is faster and gives reasonable results.

    % Compute the top eigenvalue and eigenvector of off-diag(cov(Fxq - q)).
    cov_Fxq_q = full(Fxq_minus_q' * Fxq_minus_q) / N;
    cov_Fxq_q = cov_Fxq_q - diag(diag(cov_Fxq_q));
    [v1, lambda1] = eigs(cov_Fxq_q, 1);
    % Project the (expanded) samples along the direction v1.
    projection_data_pair = [abs(Fxq_minus_q * v1) X];
    % Sort by the absolute value of the projection (first column).
    sorted_pair = sortrows(projection_data_pair);
    % Remove eps-fraction of the sample farthest from the projected mean.
    i = round((1-eps)*N);
    X = sorted_pair(1:i, 2:end);

    p_filter = empirical_bn(parent, X);
    fprintf('\td_TV(p, p_filter) = %f\n', dtv_bn(parent, p, p_filter))

    fprintf('\t\t%f fraction of the filtered samples are noise\n', 1 - size(intersect(X, Y, 'rows'), 1) / (eps*N));
end